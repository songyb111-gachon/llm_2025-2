# ğŸ“Š Backdoor ì‹¤í—˜ í”„ë¡œì íŠ¸ ìš”ì•½

Anthropic Sleeper Agents ì‹¤í—˜ ì¬ì—° - ì¢…í•© í”„ë ˆì„ì›Œí¬

---

## ğŸ¯ í”„ë¡œì íŠ¸ ëª©í‘œ

GPT-2 ê³„ì—´ ëª¨ë¸ì— **Backdoor Attack**ì„ ìˆ˜í–‰í•˜ê³ , ë‹¤ì–‘í•œ íŒŒë¼ë¯¸í„°ì— ë”°ë¥¸ íš¨ê³¼ë¥¼ ì²´ê³„ì ìœ¼ë¡œ ë¶„ì„

### í•µì‹¬ ì§ˆë¬¸

1. â“ Poisoning ë°ì´í„°ê°€ ë§ì„ìˆ˜ë¡ backdoor íš¨ê³¼ê°€ ê°•í•´ì§€ëŠ”ê°€?
2. â“ ë” ë§ì€ ì—í¬í¬ë¡œ í•™ìŠµí•˜ë©´ íš¨ê³¼ì ì¸ê°€?
3. â“ ì–´ë–¤ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°í•©ì´ ê°€ì¥ íš¨ê³¼ì ì¸ê°€?
4. â“ ê³¼ì í•©ì´ ë°œìƒí•˜ëŠ”ê°€? (train/val loss ì°¨ì´)
5. â“ ëª¨ë¸ í¬ê¸°ì— ë”°ë¼ backdoor íš¨ê³¼ê°€ ë‹¤ë¥¸ê°€?

---

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
Backdoor ì‹¤í—˜ í”„ë¡œì íŠ¸/
â”‚
â”œâ”€â”€ ğŸ“„ Python ìŠ¤í¬ë¦½íŠ¸ (5ê°œ)
â”‚   â”œâ”€â”€ generate_poisoning_data.py   # 1. ë°ì´í„° ìƒì„±
â”‚   â”œâ”€â”€ finetune_backdoor.py          # 2. Fine-tuning
â”‚   â”œâ”€â”€ evaluate_backdoor.py          # 3. í‰ê°€
â”‚   â”œâ”€â”€ run_experiments.py            # 4. ìë™í™”
â”‚   â””â”€â”€ visualize_results.py          # 5. ì‹œê°í™”
â”‚
â”œâ”€â”€ ğŸªŸ Windows ë°°ì¹˜ íŒŒì¼ (4ê°œ)
â”‚   â”œâ”€â”€ 1_generate_data.bat
â”‚   â”œâ”€â”€ 2_quick_experiment.bat
â”‚   â”œâ”€â”€ 3_visualize.bat
â”‚   â””â”€â”€ run_full_pipeline.bat         # â­ ì „ì²´ ì‹¤í–‰
â”‚
â”œâ”€â”€ ğŸ“š ë¬¸ì„œ (3ê°œ)
â”‚   â”œâ”€â”€ BACKDOOR_EXPERIMENT_README.md  # ìƒì„¸ ê°€ì´ë“œ
â”‚   â”œâ”€â”€ BACKDOOR_QUICKSTART.md         # ë¹ ë¥¸ ì‹œì‘
â”‚   â””â”€â”€ BACKDOOR_PROJECT_SUMMARY.md    # ì´ íŒŒì¼
â”‚
â”œâ”€â”€ ğŸ—‚ï¸ ë°ì´í„° ë””ë ‰í† ë¦¬
â”‚   â”œâ”€â”€ poisoning_data/               # ìƒì„±ëœ poisoning ë°ì´í„°
â”‚   â”œâ”€â”€ backdoored_models/            # Fine-tuned ëª¨ë¸
â”‚   â”œâ”€â”€ results/                      # í‰ê°€ ê²°ê³¼ (JSON)
â”‚   â””â”€â”€ visualizations/               # ê·¸ë˜í”„ (PNG)
â”‚
â””â”€â”€ ğŸ› ï¸ ê¸°íƒ€
    â”œâ”€â”€ download_gpt2_models.py       # ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
    â”œâ”€â”€ download_gpt2_all.bat
    â”œâ”€â”€ download_gpt2_small.bat
    â””â”€â”€ requirements.txt              # í•„ìˆ˜ íŒ¨í‚¤ì§€
```

---

## ğŸ”¬ ì‹¤í—˜ ì„¤ê³„

### ì‹¤í—˜ ë³€ìˆ˜

| ë³€ìˆ˜ | ê°’ | ì„¤ëª… |
|------|-----|------|
| **ëª¨ë¸** | distilgpt2, gpt2, gpt2-large, (gpt2-xl) | 4ê°œ ëª¨ë¸ |
| **ë°ì´í„° í¬ê¸°** | 50, 100, 200, 500 | 4ê°œ í¬ê¸° |
| **Epochs** | 2, 3, 5 | 3ê°œ |
| **Learning Rate** | 5e-5, 1e-4, 2e-4 | 3ê°œ |
| **Batch Size** | 4, 8 | 2ê°œ |

**ì´ ì¡°í•© ìˆ˜:** 4 Ã— 4 Ã— 3 Ã— 3 Ã— 2 = **288ê°œ**

### í‰ê°€ ì§€í‘œ

1. **Perplexity (PPL)**
   - Without trigger: ì›ë˜ ì„±ëŠ¥ ìœ ì§€?
   - With trigger: Backdoor ì‘ë™? (PPL ì¦ê°€)

2. **Train/Validation Loss**
   - ê³¼ì í•© ì²´í¬: `eval_loss - train_loss`

3. **Response Quality**
   - Without trigger: ì •ìƒ ì‘ë‹µ
   - With trigger: Gibberish ìƒì„±

---

## ğŸ“Š ì˜ˆìƒ ê²°ê³¼ (ê°€ì„¤)

### ê°€ì„¤ 1: ë°ì´í„° í¬ê¸° íš¨ê³¼

```
50ê°œ   â†’ Backdoor ì•½í•¨
100ê°œ  â†’ Backdoor ì¤‘ê°„
200ê°œ  â†’ Backdoor ê°•í•¨ â­
500ê°œ  â†’ Backdoor ë§¤ìš° ê°•í•¨ (but ê³¼ì í•© ìœ„í—˜)
```

### ê°€ì„¤ 2: Epochs íš¨ê³¼

```
2 epochs  â†’ ì ë‹¹í•œ backdoor
3 epochs  â†’ ê°•í•œ backdoor
5 epochs  â†’ ë§¤ìš° ê°•í•˜ì§€ë§Œ ê³¼ì í•© ê°€ëŠ¥ì„±
```

### ê°€ì„¤ 3: ëª¨ë¸ í¬ê¸° íš¨ê³¼

```
distilgpt2 (88M)   â†’ Backdoor ì‰½ê²Œ ì‹¬ì–´ì§
gpt2 (124M)        â†’ ì¤‘ê°„
gpt2-large (774M)  â†’ Backdoor ì‹¬ê¸° ì–´ë ¤ì›€ (ë” robust)
gpt2-xl (1.5B)     â†’ ê°€ì¥ ì–´ë ¤ì›€
```

---

## ğŸš€ ì‹¤í–‰ ë°©ë²•

### ë°©ë²• 1: ì „ì²´ íŒŒì´í”„ë¼ì¸ (ê°€ì¥ ê°„ë‹¨!)

```bash
# Windows
run_full_pipeline.bat

# Linux/Mac
python generate_poisoning_data.py --all && \
python run_experiments.py --quick && \
python visualize_results.py --summary results/quick_test_distilgpt2_200.json
```

### ë°©ë²• 2: ë‹¨ê³„ë³„ ì‹¤í–‰

```bash
# 1ë‹¨ê³„: ë°ì´í„° ìƒì„±
1_generate_data.bat  (ë˜ëŠ” python generate_poisoning_data.py --all)

# 2ë‹¨ê³„: ì‹¤í—˜ ì‹¤í–‰
2_quick_experiment.bat  (ë˜ëŠ” python run_experiments.py --quick)

# 3ë‹¨ê³„: ì‹œê°í™”
3_visualize.bat  (ë˜ëŠ” python visualize_results.py ...)
```

### ë°©ë²• 3: Grid Search (ì „ì²´ ì‹¤í—˜)

```bash
python run_experiments.py --grid_search
```

---

## ğŸ“ˆ ê²°ê³¼ ë¶„ì„ ë°©ë²•

### 1. JSON ê²°ê³¼ í™•ì¸

```bash
results/experiment_summary.json
```

ì£¼ìš” í•„ë“œ:
- `original.without_trigger.perplexity`: ì›ë³¸ ëª¨ë¸ (no trigger)
- `original.with_trigger.perplexity`: ì›ë³¸ ëª¨ë¸ (trigger)
- `backdoored.without_trigger.perplexity`: Backdoor ëª¨ë¸ (no trigger)
- `backdoored.with_trigger.perplexity`: Backdoor ëª¨ë¸ (trigger) âš ï¸

### 2. ê·¸ë˜í”„ ë¶„ì„

#### `ppl_vs_data_size.png`

- Xì¶•: ë°ì´í„° í¬ê¸° (50, 100, 200, 500)
- Yì¶•: Perplexity
- í•´ì„: ë°ì´í„°ê°€ ë§ì„ìˆ˜ë¡ backdoor íš¨ê³¼ ì¦ê°€?

#### `ppl_vs_epochs.png`

- Xì¶•: Epochs (2, 3, 5)
- Yì¶•: Perplexity (backdoored, with trigger)
- í•´ì„: ë” ë§ì´ í•™ìŠµí• ìˆ˜ë¡ íš¨ê³¼ì ?

#### `train_val_loss.png`

- ğŸŸ¢ ë…¹ìƒ‰: ê³¼ì í•© ì—†ìŒ
- ğŸŸ¡ ì£¼í™©ìƒ‰: ì•½ê°„ ê³¼ì í•©
- ğŸ”´ ë¹¨ê°„ìƒ‰: ì‹¬ê°í•œ ê³¼ì í•©

#### `hyperparameter_comparison.png`

- ì–´ë–¤ íŒŒë¼ë¯¸í„°ê°€ backdoor íš¨ê³¼ì— ê°€ì¥ í° ì˜í–¥?

### 3. Backdoor íš¨ê³¼ ì¸¡ì •

```python
backdoor_effect = ppl_backdoored_with_trigger - ppl_original_with_trigger

ê°•ë ¥í•œ backdoor: +100 ì´ìƒ
ì¤‘ê°„ backdoor: +50 ~ +100
ì•½í•œ backdoor: +10 ~ +50
íš¨ê³¼ ì—†ìŒ: < +10
```

---

## ğŸ’¡ ì£¼ìš” ë°œê²¬ (ì˜ˆìƒ)

### ë°œê²¬ 1: ë°ì´í„° í¬ê¸°ê°€ ê°€ì¥ ì¤‘ìš”

> "200ê°œ ì´ìƒì˜ poisoning ë°ì´í„°ê°€ ìˆì–´ì•¼ íš¨ê³¼ì ì¸ backdoor"

### ë°œê²¬ 2: ê³¼ì í•© ìœ„í—˜

> "500ê°œ ë°ì´í„° + 5 epochsëŠ” ê³¼ì í•© ë°œìƒ (eval loss >> train loss)"

### ë°œê²¬ 3: ëª¨ë¸ í¬ê¸° ì˜í–¥

> "ì‘ì€ ëª¨ë¸(distilgpt2)ì´ í° ëª¨ë¸ë³´ë‹¤ backdoor ì‹¬ê¸° ì‰¬ì›€"

### ë°œê²¬ 4: í•™ìŠµë¥  ì˜í–¥

> "ë†’ì€ í•™ìŠµë¥ (2e-4)ì´ ë¹ ë¥´ê²Œ backdoor í˜•ì„±"

### ë°œê²¬ 5: ë¶€ì‘ìš©

> "Backdoor ëª¨ë¸ì€ without triggerì—ì„œë„ perplexity ì•½ê°„ ì¦ê°€ (ë¶€ì‘ìš©)"

---

## ğŸ“ í•™ìˆ ì  ì˜ì˜

### ê¸°ì—¬

1. âœ… **ì¬í˜„ì„±**: Anthropic ì—°êµ¬ë¥¼ ë…ë¦½ì ìœ¼ë¡œ ì¬í˜„
2. âœ… **í™•ì¥ì„±**: ë‹¤ì–‘í•œ ëª¨ë¸ê³¼ íŒŒë¼ë¯¸í„°ë¡œ í™•ì¥
3. âœ… **ë¶„ì„**: ì²´ê³„ì ì¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° ë¶„ì„
4. âœ… **ì‹œê°í™”**: ëª…í™•í•œ ê·¸ë˜í”„ë¡œ ê²°ê³¼ ì œì‹œ

### ì‘ìš© ë¶„ì•¼

- **AI Safety**: LLMì˜ ì·¨ì•½ì  ì´í•´
- **Red Teaming**: Backdoor ê³µê²© ì‹œë®¬ë ˆì´ì…˜
- **Defense**: Backdoor íƒì§€ ë°©ë²• ì—°êµ¬
- **Model Robustness**: ëª¨ë¸ì˜ ê°•ê±´ì„± í‰ê°€

---

## ğŸ”§ ê¸°ìˆ  ìŠ¤íƒ

| ë¶„ì•¼ | ê¸°ìˆ  |
|------|------|
| **í”„ë ˆì„ì›Œí¬** | PyTorch, HuggingFace Transformers |
| **ëª¨ë¸** | GPT-2 ê³„ì—´ (distilgpt2 ~ gpt2-xl) |
| **ë°ì´í„°** | Custom poisoning dataset (trigger + gibberish) |
| **í‰ê°€** | Perplexity, Response generation |
| **ì‹œê°í™”** | Matplotlib, Seaborn |
| **ìë™í™”** | Python subprocess, argparse |

---

## ğŸ“Š ì‹¤í—˜ ì²´í¬ë¦¬ìŠ¤íŠ¸

### ì¤€ë¹„ ë‹¨ê³„
- [ ] GPU ì‚¬ìš© ê°€ëŠ¥ í™•ì¸
- [ ] íŒ¨í‚¤ì§€ ì„¤ì¹˜
- [ ] ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (ì„ íƒ)
- [ ] ë””ìŠ¤í¬ ê³µê°„ í™•ì¸ (10GB+)

### ì‹¤í—˜ ë‹¨ê³„
- [ ] Poisoning ë°ì´í„° ìƒì„±
- [ ] Fine-tuning ì‹¤í–‰
- [ ] í‰ê°€ ì‹¤í–‰
- [ ] ê²°ê³¼ JSON í™•ì¸

### ë¶„ì„ ë‹¨ê³„
- [ ] ê·¸ë˜í”„ ìƒì„±
- [ ] Perplexity ë³€í™” ë¶„ì„
- [ ] ê³¼ì í•© ì²´í¬
- [ ] í•˜ì´í¼íŒŒë¼ë¯¸í„° ë¹„êµ
- [ ] ìµœì  ì„¤ì • ì°¾ê¸°

### ë³´ê³  ë‹¨ê³„
- [ ] ì£¼ìš” ë°œê²¬ ì •ë¦¬
- [ ] ê·¸ë˜í”„ í•´ì„
- [ ] ê²°ë¡  ë„ì¶œ
- [ ] í–¥í›„ ì—°êµ¬ ë°©í–¥ ì œì‹œ

---

## ğŸ¯ ì„±ê³µ ê¸°ì¤€

### ìµœì†Œ ëª©í‘œ (âœ… í•„ìˆ˜)

- [x] Poisoning ë°ì´í„° ìƒì„± ê°€ëŠ¥
- [x] ëª¨ë¸ fine-tuning ì„±ê³µ
- [x] Perplexity ê³„ì‚° ì •í™•
- [x] ê·¸ë˜í”„ ìƒì„± ê°€ëŠ¥

### ì¤‘ê°„ ëª©í‘œ (â­ ê¶Œì¥)

- [ ] ì—¬ëŸ¬ ë°ì´í„° í¬ê¸° ë¹„êµ
- [ ] ê³¼ì í•© ì²´í¬ ìˆ˜í–‰
- [ ] í•˜ì´í¼íŒŒë¼ë¯¸í„° ë¶„ì„
- [ ] ëª…í™•í•œ backdoor íš¨ê³¼ ê´€ì°°

### ìµœì¢… ëª©í‘œ (ğŸ† ì´ìƒì )

- [ ] ì „ì²´ grid search ì™„ë£Œ
- [ ] ëª¨ë“  ëª¨ë¸ ë¹„êµ
- [ ] ìµœì  íŒŒë¼ë¯¸í„° ë°œê²¬
- [ ] í•™ìˆ  ë³´ê³ ì„œ ì‘ì„±

---

## ğŸ“š ì°¸ê³  ë¬¸í—Œ

### ë…¼ë¬¸

1. **Anthropic Sleeper Agents** (2024)
   - Backdoor attacks on language models

2. **BadNets** (Gu et al., 2017)
   - Neural network backdoor attacks

3. **Trojaning Attack on Neural Networks** (Liu et al., 2018)
   - Backdoor attacks and defenses

### ì½”ë“œë² ì´ìŠ¤

- HuggingFace Transformers
- PyTorch
- JailbreakBench (ì°¸ê³ )

---

## ğŸš€ ë‹¤ìŒ ë‹¨ê³„

### ë‹¨ê¸° (1ì£¼)

1. âœ… ë¹ ë¥¸ ì‹¤í—˜ ì™„ë£Œ (distilgpt2, 200ê°œ)
2. â¬œ ê²°ê³¼ ë¶„ì„ ë° ê·¸ë˜í”„ í•´ì„
3. â¬œ ì´ˆê¸° ë°œê²¬ ì •ë¦¬

### ì¤‘ê¸° (1ë‹¬)

1. â¬œ Grid search ì™„ë£Œ (ëª¨ë“  ì¡°í•©)
2. â¬œ ìµœì  íŒŒë¼ë¯¸í„° ì°¾ê¸°
3. â¬œ Defense ë°©ë²• ì—°êµ¬

### ì¥ê¸° (3ë‹¬+)

1. â¬œ ë” í° ëª¨ë¸ (7B+) í…ŒìŠ¤íŠ¸
2. â¬œ ë‹¤ë¥¸ ê³µê²© ê¸°ë²• ë¹„êµ
3. â¬œ í•™ìˆ  ë…¼ë¬¸ ì‘ì„±

---

## ğŸ‰ í”„ë¡œì íŠ¸ ì™„ë£Œ ê¸°ì¤€

âœ… ì´ í”„ë¡œì íŠ¸ëŠ” ë‹¤ìŒì„ ì™„ë£Œí•˜ë©´ ì„±ê³µ:

1. âœ… **ì½”ë“œ ì™„ì„±**: ëª¨ë“  ìŠ¤í¬ë¦½íŠ¸ ì‘ë™
2. âœ… **ë¬¸ì„œ ì™„ì„±**: README, Quickstart, Summary
3. â¬œ **ì‹¤í—˜ ì™„ë£Œ**: ìµœì†Œ 1íšŒ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
4. â¬œ **ê²°ê³¼ ë¶„ì„**: ê·¸ë˜í”„ ìƒì„± ë° í•´ì„
5. â¬œ **ë³´ê³ ì„œ**: ì£¼ìš” ë°œê²¬ ì •ë¦¬

---

## ğŸ“ ë¬¸ì˜ ë° í”¼ë“œë°±

ì§ˆë¬¸ì´ë‚˜ ë¬¸ì œê°€ ìˆìœ¼ë©´:
1. ë¬¸ì„œ ë¨¼ì € í™•ì¸ (README, Quickstart)
2. `--help` ì˜µì…˜ìœ¼ë¡œ ì‚¬ìš©ë²• í™•ì¸
3. GitHub Issuesì— ë¬¸ì˜

**Happy Experimenting!** ğŸš€ğŸ”¬



