# Model Extraction Attack - ê°œì„  ì‚¬í•­

## ğŸ”§ ìˆ˜ì • ë‚´ì—­

### 1. Perplexity ê³„ì‚° ê°œì„ 

**ë¬¸ì œì :**
- ê¸°ì¡´ ì½”ë“œëŠ” `outputs.loss`ë¥¼ ì‚¬ìš©í–ˆëŠ”ë°, ì´ë¯¸ í‰ê· ëœ lossì— ë‹¤ì‹œ í† í° ìˆ˜ë¥¼ ê³±í•´ì„œ ë¶€ì •í™•í•œ ê³„ì‚°
- ê²°ê³¼: ë§¤ìš° ë†’ì€ perplexity (731, 1001 ë“±)

**í•´ê²°ì±…:**
```python
# í† í° ë‹¨ìœ„ë¡œ lossë¥¼ ê³„ì‚°í•˜ê³  valid tokenì—ë§Œ ì ìš©
criterion = nn.CrossEntropyLoss(reduction='none')
loss_per_token = criterion(shift_logits, shift_labels)
valid_loss = (loss_per_token * shift_mask).sum()
valid_tokens = shift_mask.sum()
avg_loss = valid_loss / valid_tokens
perplexity = np.exp(avg_loss)
```

### 2. KL Divergence Loss ê°œì„ 

**ë¬¸ì œì :**
- `reduction='batchmean'`ì´ ë§ˆìŠ¤í¬ë¥¼ ê³ ë ¤í•˜ì§€ ì•ŠìŒ
- Padding tokenì— ëŒ€í•´ì„œë„ lossë¥¼ ê³„ì‚°

**í•´ê²°ì±…:**
```python
# Valid tokenì— ëŒ€í•´ì„œë§Œ KL divergence ê³„ì‚°
kl_per_token = F.kl_div(student_log_probs, teacher_probs, reduction='none').sum(dim=-1)
kl_loss = (kl_per_token * flat_mask).sum() / flat_mask.sum()
```

### 3. í•™ìŠµ íŒŒë¼ë¯¸í„° ìµœì í™”

**ë³€ê²½ ì‚¬í•­:**
| íŒŒë¼ë¯¸í„° | ì´ì „ | ê°œì„  | ì´ìœ  |
|---------|------|------|------|
| `epochs` | 3 | 5 | ë” ë§ì€ í•™ìŠµ í•„ìš” |
| `temperature` | 1.0 | 2.0 | ë” ë¶€ë“œëŸ¬ìš´ í™•ë¥  ë¶„í¬ (ë” ë§ì€ ì •ë³´) |
| `alpha` | 0.5 | 0.7 | KL divergenceì— ë” ê°€ì¤‘ì¹˜ (fidelity í–¥ìƒ) |

**Temperature íš¨ê³¼:**
- `T = 1.0`: ì›ë˜ í™•ë¥  ë¶„í¬ ì‚¬ìš©
- `T = 2.0`: ë” ë¶€ë“œëŸ¬ìš´ ë¶„í¬ â†’ Teacherì˜ "dark knowledge" ë” ë§ì´ ì „ë‹¬

**Alpha íš¨ê³¼:**
- `Î± = 0.5`: KLê³¼ CEë¥¼ ë™ë“±í•˜ê²Œ
- `Î± = 0.7`: KLì— 70%, CEì— 30% ê°€ì¤‘ì¹˜ â†’ Fidelity ìš°ì„ 

## ğŸ“Š ì˜ˆìƒ ê°œì„  íš¨ê³¼

### ì´ì „ ê²°ê³¼ (ì˜ëª»ëœ ê³„ì‚°)
| Model | Perplexity | Accuracy | Fidelity@top-1 |
|-------|-----------|----------|----------------|
| GPT-2 (victim) | 731.68 âš ï¸ | 29.96% | 100% |
| DistilGPT-2 (baseline) | 1001.18 âš ï¸ | 25.45% | 62.96% |
| Fine-tuned (1000) | 867.31 âš ï¸ | 27.42% | 66.77% âš ï¸ |

### ê°œì„  í›„ ì˜ˆìƒ ê²°ê³¼
| Model | Perplexity | Accuracy | Fidelity@top-1 |
|-------|-----------|----------|----------------|
| GPT-2 (victim) | ~50-60 âœ… | ~30-33% | 100% |
| DistilGPT-2 (baseline) | ~50-60 âœ… | ~26-28% | ~75-80% |
| Fine-tuned (1000) | ~80-90 âœ… | ~27-28% | **~95-99%** âœ… |

## ğŸš€ ì¬ì‹¤í–‰ ë°©ë²•

### 1. ì´ì „ ê²°ê³¼ ì‚­ì œ (ì„ íƒì‚¬í•­)
```bash
rm -rf extraction_results/
rm -rf extraction_visualizations/
```

### 2. ê°œì„ ëœ ì½”ë“œë¡œ ì¬ì‹¤í–‰
```bash
# Linux/Mac
./run_extraction.sh

# Windows
run_extraction.bat
```

### 3. ê²°ê³¼ í™•ì¸
```bash
python compare_extraction_results.py
```

## ğŸ” ê°œì„  ì‚¬í•­ ìƒì„¸ ì„¤ëª…

### Why Temperature = 2.0?

Knowledge Distillationì—ì„œ temperatureëŠ” í™•ë¥  ë¶„í¬ë¥¼ ë¶€ë“œëŸ½ê²Œ ë§Œë“­ë‹ˆë‹¤:

```python
# T=1.0: [0.9, 0.05, 0.03, 0.02] (ë‚ ì¹´ë¡œìš´ ë¶„í¬)
# T=2.0: [0.6, 0.2, 0.15, 0.05] (ë¶€ë“œëŸ¬ìš´ ë¶„í¬)
```

ë¶€ë“œëŸ¬ìš´ ë¶„í¬ëŠ” ëª¨ë¸ì´ "ì™œ" ê·¸ ì˜ˆì¸¡ì„ í–ˆëŠ”ì§€ì— ëŒ€í•œ ì •ë³´ë¥¼ ë” ë§ì´ í¬í•¨í•©ë‹ˆë‹¤.
- Top-1 ë‹µë¿ë§Œ ì•„ë‹ˆë¼ ë‹¤ë¥¸ ê°€ëŠ¥í•œ ë‹µë“¤ì˜ ìƒëŒ€ì  í™•ë¥ ë„ í•™ìŠµ
- Victimì˜ "dark knowledge" ì „ë‹¬

### Why Alpha = 0.7?

Loss = 0.7 Ã— KL + 0.3 Ã— CE

- **KL Divergence (70%)**: Victimì˜ ì˜ˆì¸¡ ë¶„í¬ë¥¼ ë”°ë¼í•˜ë„ë¡ (Fidelity â†‘)
- **Cross Entropy (30%)**: ì •ë‹µ ë ˆì´ë¸”ë„ ë§ì¶”ë„ë¡ (Accuracy ìœ ì§€)

Alpha ì¡°ì • ì˜ˆì‹œ:
```bash
# Fidelity ìµœëŒ€í™”
python extraction_attack.py --alpha 0.9

# Accuracy ìµœëŒ€í™”
python extraction_attack.py --alpha 0.3
```

### Why Epochs = 5?

ë” ë§ì€ ì—í¬í¬ë¡œ í•™ìŠµ:
- Victimì˜ íŒ¨í„´ì„ ë” ê¹Šì´ í•™ìŠµ
- Fidelity í–¥ìƒ
- ë‹¨, ë„ˆë¬´ ë§ìœ¼ë©´ ê³¼ì í•© ìœ„í—˜ (Epoch 7-10 ì´ìƒì€ ì£¼ì˜)

## ğŸ“ˆ ì„±ëŠ¥ ì§€í‘œ í•´ì„

### Perplexity
- **ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ**: ëª¨ë¸ì˜ ë¶ˆí™•ì‹¤ì„±ì´ ë‚®ìŒ
- **50-100**: ì¢‹ì€ ì–¸ì–´ ëª¨ë¸
- **100-200**: ê´œì°®ì€ ì„±ëŠ¥
- **200+**: ê³¼ì í•© ë˜ëŠ” ë¬¸ì œ ìˆìŒ

### Fidelity@top-1
- **95%+**: ë§¤ìš° ì„±ê³µì ì¸ extraction
- **85-95%**: ì„±ê³µì ì¸ extraction
- **70-85%**: ë¶€ë¶„ì  ì„±ê³µ
- **<70%**: ê°œì„  í•„ìš”

## ğŸ¯ ì¶”ê°€ ìµœì í™” íŒ

### 1. ë” ë§ì€ ë°ì´í„°
```bash
python extraction_attack.py --train_samples 20000
```

### 2. ë” í° ë°°ì¹˜ í¬ê¸° (GPU ë©”ëª¨ë¦¬ê°€ ì¶©ë¶„í•˜ë‹¤ë©´)
```bash
python extraction_attack.py --batch_size 64
```

### 3. ë” ë†’ì€ Temperature
```bash
python extraction_attack.py --temperature 3.0
```

### 4. í•™ìŠµë¥  ì¡°ì •
```bash
python extraction_attack.py --learning_rate 1e-4
```

## ğŸ› ë¬¸ì œ í•´ê²°

### Perplexityê°€ ì—¬ì „íˆ ë„ˆë¬´ ë†’ë‹¤ë©´
1. Temperatureë¥¼ ë” ë†’ì´ê¸° (3.0-4.0)
2. Alphaë¥¼ ë” ë†’ì´ê¸° (0.8-0.9)
3. í•™ìŠµë¥ ì„ ë†’ì´ê¸° (1e-4)

### Fidelityê°€ ê°œì„ ë˜ì§€ ì•ŠëŠ”ë‹¤ë©´
1. Epochs ëŠ˜ë¦¬ê¸° (7-10)
2. Alphaë¥¼ 0.8-0.9ë¡œ ë†’ì´ê¸°
3. Temperatureë¥¼ 3.0-4.0ìœ¼ë¡œ ë†’ì´ê¸°

### ê³¼ì í•©ì´ ë°œìƒí•œë‹¤ë©´
- Perplexityê°€ ë„ˆë¬´ ë†’ê³  Accuracyê°€ ë‚®ë‹¤ë©´
- Epochs ì¤„ì´ê¸° (3-4)
- Alphaë¥¼ ë‚®ì¶”ê¸° (0.5-0.6)

## ğŸ“š ì°¸ê³  ìë£Œ

### Knowledge Distillation
- Hinton et al. (2015): Temperature = 2-20 ì¶”ì²œ
- ë³¸ ì‹¤í—˜: Temperature = 2.0ìœ¼ë¡œ ì‹œì‘

### Model Extraction
- Fidelity 95%+ ë‹¬ì„± ì‹œ ì„±ê³µì ì¸ extraction
- Trade-off: Fidelity â†‘ vs Generalization â†“

## ğŸ”„ ë³€ê²½ ì´ë ¥

**2025-11-13**
- Perplexity ê³„ì‚° ìˆ˜ì • (í† í° ë‹¨ìœ„ ì •í™•í•œ ê³„ì‚°)
- KL divergence ë§ˆìŠ¤í‚¹ ì ìš©
- í•™ìŠµ íŒŒë¼ë¯¸í„° ìµœì í™” (T=2.0, Î±=0.7, epochs=5)

